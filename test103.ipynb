{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cce1ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spekpy is not install, you won't be able to load a beam spectrum using spekpy\n",
      "SimpleGVXR 2.0.6 (2023-05-23T20:42:48) [Compiler: Microsoft Visual Studio] on Windows\n",
      "gVirtualXRay core library (gvxr) 2.0.6 (2023-05-23T20:43:44) [Compiler: Microsoft Visual Studio] on Windows\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, math\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import cma\n",
    "from PIL import Image\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "from gvxrPython3 import gvxr\n",
    "from gvxrPython3 import json2gvxr\n",
    "\n",
    "from gvxrPython3.utils import visualise # Visualise the 3D environment if k3D is supported\n",
    "from gvxrPython3.utils import plotScreenshot # Visualise the 3D environment using Matplotlib\n",
    "\n",
    "from gvxrPython3.utils import loadSpekpySpectrum # Generate and load an X-ray spectrum using Spekpy\n",
    "from gvxrPython3.utils import loadXpecgenSpectrum # Generate and load an X-ray spectrum using xpecgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67345566",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_padding = True\n",
    "pad_width = 50\n",
    "angular_step_in_deg = 3.6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01cf6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"C:/Users/user/phd/Dataoff/\"\n",
    "# data_path = \"C:/Users/user/phd/26SepImages/\"\n",
    "# data_path = \"C:/Users/snn23kfl/project/\"\n",
    "#data_path = \"4thOCtober_image/\"\n",
    "#data_path = \"4thCotober_imageAngle/\"\n",
    "#data_path = \"23OctoberImage/\"\n",
    "data_path = \"25OctoberData/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa45dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snn23kfl\\project\n"
     ]
    }
   ],
   "source": [
    "current_folder = str(globals()['_dh'][0])\n",
    "print(current_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cddfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_images(image_paths):\n",
    "    \n",
    "    \"\"\"Average a list of images.\"\"\"\n",
    "  \n",
    "    # Load the first image to get the shape\n",
    "    sample_image = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "    if sample_image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_paths[0]}\")\n",
    "    \n",
    "    avg_image = np.zeros_like(sample_image, dtype=float)\n",
    "    \n",
    "    if use_padding:\n",
    "        avg_image = np.pad(avg_image, (pad_width, pad_width), mode='median')\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {path}\")\n",
    "\n",
    "        if use_padding:\n",
    "            median_value = np.median(image)\n",
    "            image = np.pad(image, (pad_width, pad_width), 'constant', constant_values=(median_value, median_value))\n",
    "\n",
    "        avg_image += image.astype(float)\n",
    "    \n",
    "    avg_image /= len(image_paths)\n",
    "    \n",
    "    return cv2.medianBlur(avg_image.astype(np.single), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83860b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatField(img, white, dark, epsilon=0.0):\n",
    "\n",
    "    temp_white = np.copy(white)\n",
    "    temp_img = np.copy(img)\n",
    "    \n",
    "    test = white - dark == 0\n",
    "    temp_white[test] += 1\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        temp_img[test] += 1\n",
    "        return (temp_img - dark + epsilon) / (temp_white - dark + epsilon)\n",
    "    elif len(img.shape) == 3:\n",
    "        flat = np.zeros(img.shape, dtype=np.single)\n",
    "        for i, proj in enumerate(temp_img):\n",
    "            proj[test] += 1\n",
    "            flat[i] = (proj - dark + epsilon) / (temp_white - dark + epsilon)\n",
    "        return flat\n",
    "    else:\n",
    "        raise IOError(\"Bad image dimension: \" + str(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdb9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for my recently acquired images stored in PhD file\n",
    "\n",
    "\n",
    "\n",
    "dark_field_paths = glob.glob(data_path + '/darkfd/darkfd_*.tiff')\n",
    "dark_field_paths = natsorted(dark_field_paths, key=lambda y: y.lower())\n",
    "\n",
    "white_field_paths = glob.glob(data_path + '/whitefd/whitefd_*.tiff')\n",
    "white_field_paths = natsorted(white_field_paths, key=lambda y: y.lower())\n",
    "\n",
    "raw_image_paths = glob.glob(data_path + '/raw_images/raw_image_*.tiff')\n",
    "raw_image_paths = natsorted(raw_image_paths, key=lambda y: y.lower())\n",
    "\n",
    "if len(raw_image_paths) == 0:\n",
    "    raw_image_paths = glob.glob(data_path + '/rawimages/raw_images_*.jpg')\n",
    "    raw_image_paths = natsorted(raw_image_paths, key=lambda y: y.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67c667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average the dark field and white field images\n",
    "I_dark = average_images(dark_field_paths)\n",
    "I_white = average_images(white_field_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "525f33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_raw = []\n",
    "angles_in_deg = []\n",
    "for i, fname in enumerate(raw_image_paths):\n",
    "    angle = angular_step_in_deg * i\n",
    "    print(f\"Processing image {i}: Angle = {angle}\")  # Debug print\n",
    "\n",
    "    if angle < 360.000001:\n",
    "        angles_in_deg.append(angular_step_in_deg * i)\n",
    "        image = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Image read failed: {fname}\")\n",
    "        else:\n",
    "            if use_padding:\n",
    "                median_value = np.median(image)\n",
    "                image = np.pad(image, (pad_width, pad_width), 'constant', constant_values=(median_value, median_value))\n",
    "            I_raw.append(image)\n",
    "\n",
    "print(f\"Number of images after processing: {len(I_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e458ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images, base_path, prefix):\n",
    "    \"\"\"\n",
    "    Saves an array of images to files with incremental indices.\n",
    "\n",
    "    Args:\n",
    "    - images (numpy.ndarray): An array of images to save.\n",
    "    - base_path (str): The base directory where the images will be saved.\n",
    "    - prefix (str): A prefix for the saved image filenames.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Create the base path if it does not exist\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    # Save each image in the array\n",
    "    for i, image in enumerate(images):\n",
    "        filename = os.path.join(base_path, f\"{prefix}_{i:04d}.tiff\")\n",
    "        cv2.imwrite(filename, image)\n",
    "\n",
    "    print(f\"All images saved with prefix {prefix} in {base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbebfd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_path = os.path.join(data_path, \"corrected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8008089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images saved with prefix corrected_flatfield_zeros in 25OctoberData/corrected\n"
     ]
    }
   ],
   "source": [
    "# Save the flat-field corrected images using zeros as dark field\n",
    "save_images(I_flat2, corrected_path, \"corrected_flatfield_zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b83fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0dff909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes the extra pixels are evenly distributed around the image\n",
    "crop_x = (I_dark.shape[1] - 640) // 2\n",
    "crop_y = (I_dark.shape[0] - 480) // 2\n",
    "I_dark_cropped = I_dark[crop_y:crop_y+480, crop_x:crop_x+640]\n",
    "I_white_cropped = I_white[crop_y:crop_y+480, crop_x:crop_x+640]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eae1a28",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 580 but corresponding boolean dimension is 480",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m I_flat1 \u001b[38;5;241m=\u001b[39m \u001b[43mflatField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI_white_cropped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI_dark_cropped\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m, in \u001b[0;36mflatField\u001b[1;34m(img, white, dark, epsilon)\u001b[0m\n\u001b[0;32m     13\u001b[0m flat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(img\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msingle)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, proj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(temp_img):\n\u001b[1;32m---> 15\u001b[0m     proj[test] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m     flat[i] \u001b[38;5;241m=\u001b[39m (proj \u001b[38;5;241m-\u001b[39m dark \u001b[38;5;241m+\u001b[39m epsilon) \u001b[38;5;241m/\u001b[39m (temp_white \u001b[38;5;241m-\u001b[39m dark \u001b[38;5;241m+\u001b[39m epsilon)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flat\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 580 but corresponding boolean dimension is 480"
     ]
    }
   ],
   "source": [
    "I_flat1 = flatField(I_raw, I_white_cropped, I_dark_cropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to save the flat-field corrected images\n",
    "flatfield_corrected_dir = 'C:/Users/snn23kfl/flat_field'\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "if not os.path.exists(flatfield_corrected_dir):\n",
    "    os.makedirs(flatfield_corrected_dir)\n",
    "\n",
    "# Now you can loop through your corrected images and save them\n",
    "for i, corrected_image in enumerate(I_flat1):\n",
    "    # Convert from float to 16-bit integer\n",
    "    corrected_image = cv2.convertScaleAbs(corrected_image * (2**16 - 1), alpha=(2**16 - 1))\n",
    "\n",
    "    # File name\n",
    "    image_name = f\"flatfield_corrected_1_{i:04d}.tif\"\n",
    "\n",
    "    # Save image\n",
    "    cv2.imwrite(os.path.join(flatfield_corrected_dir, image_name), corrected_image)\n",
    "    print(f\"Saved flat-field corrected image {image_name}\")\n",
    "\n",
    "print(\"All flat-field corrected images have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_img = I_flat1[0]  # Assume I_flat1[0] is the first corrected image\n",
    "print(\"Before scaling:\", corrected_img.min(), corrected_img.max())\n",
    "\n",
    "scaled_img = cv2.convertScaleAbs(corrected_img * (2**16 - 1), alpha=(2**16 - 1))\n",
    "print(\"After scaling:\", scaled_img.min(), scaled_img.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90d110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
